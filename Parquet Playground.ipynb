{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6282c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.7\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488498 sha256=d8645f70ea55fb6a43fff8e2e2c7ff70db1222b55a23f7a57c6a66cb2f9a2598\n",
      "  Stored in directory: /Users/shreyan/Library/Caches/pip/wheels/92/09/11/aa01d01a7f005fda8a66ad71d2be7f8aa341bddafb27eee3c7\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d61b1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4591464\r\n",
      "drwxr-xr-x  37 shreyan  staff       1184 Jul  6 22:15 \u001b[34m.\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  13 shreyan  staff        416 Jul  7 16:59 \u001b[34m..\u001b[m\u001b[m/\r\n",
      "-rw-r--r--   1 shreyan  staff     463011 Jul  6 22:15 airportdb@airplane_type@@0.csv\r\n",
      "-rw-r--r--   1 shreyan  staff     259868 Jul  6 22:13 airportdb@airport@@0.csv\r\n",
      "-rw-r--r--   1 shreyan  staff     974612 Jul  6 22:15 airportdb@airport_geo@@0.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   68318660 Jul  6 22:14 airportdb@booking@0.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   69387753 Jul  6 22:13 airportdb@booking@1.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73451383 Jul  6 22:15 airportdb@booking@10.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73430082 Jul  6 22:14 airportdb@booking@11.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73327619 Jul  6 22:15 airportdb@booking@12.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73390040 Jul  6 22:15 airportdb@booking@13.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73395914 Jul  6 22:15 airportdb@booking@14.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73419293 Jul  6 22:15 airportdb@booking@15.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73386190 Jul  6 22:15 airportdb@booking@16.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73318173 Jul  6 22:15 airportdb@booking@17.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73425652 Jul  6 22:14 airportdb@booking@18.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73381709 Jul  6 22:14 airportdb@booking@19.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   86656153 Jul  6 22:14 airportdb@booking@2.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73287373 Jul  6 22:14 airportdb@booking@20.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73305801 Jul  6 22:14 airportdb@booking@21.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73441254 Jul  6 22:14 airportdb@booking@22.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73343454 Jul  6 22:14 airportdb@booking@23.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   65045103 Jul  6 22:14 airportdb@booking@3.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   82993677 Jul  6 22:14 airportdb@booking@4.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73430950 Jul  6 22:14 airportdb@booking@5.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73316235 Jul  6 22:14 airportdb@booking@6.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73336698 Jul  6 22:14 airportdb@booking@7.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73388745 Jul  6 22:14 airportdb@booking@8.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   73294300 Jul  6 22:15 airportdb@booking@9.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   21356842 Jul  6 22:15 airportdb@booking@@24.csv\r\n",
      "-rw-r--r--   1 shreyan  staff     178673 Jul  6 22:13 airportdb@employee@@0.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   33798684 Jul  6 22:13 airportdb@flight@@0.csv\r\n",
      "-rw-r--r--   1 shreyan  staff     527777 Jul  6 22:14 airportdb@flightschedule@@0.csv\r\n",
      "-rw-r--r--   1 shreyan  staff    1036538 Jul  6 22:13 airportdb@passenger@@0.csv\r\n",
      "-rw-r--r--   1 shreyan  staff    3831502 Jul  6 22:15 airportdb@passengerdetails@@0.csv\r\n",
      "-rw-r--r--   1 shreyan  staff  233707920 Jul  6 22:15 airportdb@weatherdata@0.csv\r\n",
      "-rw-r--r--   1 shreyan  staff   31107629 Jul  6 22:15 airportdb@weatherdata@@1.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls -all csv_folder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6886180d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 29:==============>                                           (2 + 6) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------+\n",
      "|2005-01-01|00:00:00|1|0.0|99.0|1024.00|4.00|Schneefall|254|\n",
      "+----------------------------------------------------------+\n",
      "|                                      2005-01-01|00:00:...|\n",
      "|                                      2005-01-01|00:00:...|\n",
      "|                                      2005-01-01|00:00:...|\n",
      "|                                      2005-01-01|00:05:...|\n",
      "|                                      2005-01-01|00:05:...|\n",
      "|                                      2005-01-01|00:05:...|\n",
      "|                                      2005-01-01|00:05:...|\n",
      "|                                      2005-01-01|00:10:...|\n",
      "|                                      2005-01-01|00:10:...|\n",
      "|                                      2005-01-01|00:10:...|\n",
      "|                                      2005-01-01|00:10:...|\n",
      "|                                      2005-01-01|00:15:...|\n",
      "|                                      2005-01-01|00:15:...|\n",
      "|                                      2005-01-01|00:15:...|\n",
      "|                                      2005-01-01|00:15:...|\n",
      "|                                      2005-01-01|00:20:...|\n",
      "|                                      2005-01-01|00:20:...|\n",
      "|                                      2005-01-01|00:20:...|\n",
      "|                                      2005-01-01|00:20:...|\n",
      "|                                      2005-01-01|00:25:...|\n",
      "+----------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Setting up Spark session with necessary configurations\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Parquetfy\") \\\n",
    "    .config(\"spark.hadoop.fs.AbstractFileSystem.hdfs.impl\", \"org.apache.hadoop.hdfs.DistributedFileSystem\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Setting log level to ERROR to reduce log verbosity\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Reading CSV file with header and schema inference\n",
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"csv_folder/airportdb@weatherdata@0.csv\")\n",
    "\n",
    "# Displaying the content of the DataFrame\n",
    "df.show()\n",
    "\n",
    "# Writing DataFrame to Parquet format\n",
    "df.write.parquet(\"parquets/airportdb@weatherdata@0.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df8a18d",
   "metadata": {},
   "source": [
    "# Load Data to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d216cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f40b1c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"secrets.json\", 'rb') as file:\n",
    "    sql_credentials = json.load(file)\n",
    "\n",
    "username = sql_credentials['username']\n",
    "password = sql_credentials['password']\n",
    "hostname = sql_credentials['ip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68d06c08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from 'csv_folder/airportdb@passengerdetails@@0.csv' into table 'passengerdetails'\n",
      "Loaded data from 'csv_folder/airportdb@weatherdata@0.csv' into table 'weatherdata'\n",
      "Loaded data from 'csv_folder/airportdb@weatherdata@@1.csv' into table 'weatherdata'\n",
      "Loaded data from 'csv_folder/airportdb@airport_geo@@0.csv' into table 'airport_geo'\n",
      "Loaded data from 'csv_folder/airportdb@booking@14.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@airplane_type@@0.csv' into table 'airplane_type'\n",
      "Loaded data from 'csv_folder/airportdb@booking@15.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@@24.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@17.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@16.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@12.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@13.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@11.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@8.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@9.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@10.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@21.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@4.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@flightschedule@@0.csv' into table 'flightschedule'\n",
      "Loaded data from 'csv_folder/airportdb@booking@5.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@20.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@22.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@7.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@6.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@23.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@2.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@3.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@18.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@1.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@0.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@booking@19.csv' into table 'booking'\n",
      "Loaded data from 'csv_folder/airportdb@passenger@@0.csv' into table 'passenger'\n",
      "Loaded data from 'csv_folder/airportdb@employee@@0.csv' into table 'employee'\n",
      "Loaded data from 'csv_folder/airportdb@airport@@0.csv' into table 'airport'\n",
      "Loaded data from 'csv_folder/airportdb@flight@@0.csv' into table 'flight'\n",
      "Data loading completed.\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where the CSV files are located\n",
    "csv_directory = \"csv_folder\"\n",
    "\n",
    "# Initialize a MySQL connection\n",
    "connection = mysql.connector.connect(\n",
    "    user=username\n",
    "    , password=password\n",
    "    , host=hostname\n",
    "    , database='airportdb'\n",
    "    , allow_local_infile=True\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Function to extract table name from filename (excluding numbers)\n",
    "def extract_table_name(filename):\n",
    "    table_name = os.path.splitext(filename)[0]  # Remove file extension\n",
    "    table_name = re.sub(r'\\d', '', table_name)  # Remove numbers\n",
    "    return table_name\n",
    "\n",
    "# Iterate through CSV files in the directory\n",
    "for root, _, files in os.walk(csv_directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "\n",
    "            # Remove '@', '0' and 'airportdb' from the file name\n",
    "            new_file_name = os.path.basename(file).replace('@', '').replace('0', '').replace('airportdb', '')\n",
    "            \n",
    "            # Extract the table name from the file name\n",
    "            table_name = extract_table_name(new_file_name)\n",
    "\n",
    "            # Construct the full path to the CSV file\n",
    "            csv_file_path = os.path.join(root, file)\n",
    "\n",
    "            # Replace backslashes with forward slashes for Windows paths\n",
    "            # csv_file_path = tsv_file_path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "            # Define the SQL query to load data from the CSV file\n",
    "            load_data_query = f\"\"\"\n",
    "                LOAD DATA LOCAL INFILE '{csv_file_path}' \n",
    "                INTO TABLE {table_name} \n",
    "                FIELDS TERMINATED BY '|' \n",
    "                LINES TERMINATED BY '\\n';\n",
    "            \"\"\"\n",
    "\n",
    "            # Execute the SQL query to load data\n",
    "            try:\n",
    "                cursor.execute(load_data_query)\n",
    "                print(f\"Loaded data from '{csv_file_path}' into table '{table_name}'\")\n",
    "            except mysql.connector.Error as err:\n",
    "                print(f\"Error loading data from '{csv_file_path}' into table '{table_name}': {err}\")\n",
    "\n",
    "# Commit changes and close the connection\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "print(\"Data loading completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d13f576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
